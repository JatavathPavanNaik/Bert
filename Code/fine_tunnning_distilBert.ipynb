{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tune Parameters:\n",
    "    A2 and A3 appendix of Bert Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. optimizer= adam\n",
    "2. learning_rate=0.0001\n",
    "3. beta_1=0.9\n",
    "4. beta_2=0.999\n",
    "5. l2 weight decay=0.01\n",
    "6. warmup_steps = 10,000\n",
    "7. dropout_probability = 0.1\n",
    "8. activation_function = GELU\n",
    "9. batch_size = 16,32\n",
    "10. number_of_epocs = 2,3,4\n",
    "11. learning_rate(adam) = 0.00005,0.00003,0.00002\n",
    "12. max token length = 512\n",
    "13. each_word_vector_dimension=768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps:\n",
    "1. dataset preparation : balanced, cleaned\n",
    "2. load model and tokenizer\n",
    "3. TFTrainer, TFTrainingAruguments\n",
    "4. load the model and use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(r\"//Users/jatavathpavannaik/Documents/python/Bert/Twitter_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       " 1.0    72250\n",
       " 0.0    55213\n",
       "-1.0    35510\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/9v3n4s817s5g5rw62jzf3hlr0000gn/T/ipykernel_750/3977427714.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_negative[\"category\"]=2.0\n"
     ]
    }
   ],
   "source": [
    "df_negative=df[df[\"category\"]==-1]\n",
    "df_negative[\"category\"]=2.0\n",
    "df_positive=df[df[\"category\"]==1]\n",
    "df_positive=df_positive.sample(df_negative.shape[0])\n",
    "df_neutral=df[df[\"category\"]==0]\n",
    "df_neutral=df_neutral.sample(df_negative.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df_negative,df_positive,df_neutral])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "2.0    35510\n",
       "1.0    35510\n",
       "0.0    35510\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"]=df[\"clean_text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106530 entries, 0 to 111393\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  106530 non-null  object \n",
      " 1   category    106530 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=list(df[\"clean_text\"])\n",
    "y=list(df[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y, test_size = 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer= DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encoding = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85224"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encoding[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21306"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_encoding[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert tokenized inputs into tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encoding),y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encoding),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intilizaing fine_tunning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "\n",
    "training_args=TFTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_gpu_train_batch_size=16,\n",
    "    per_gpu_eval_batch_size=32,\n",
    "    eval_steps=0,\n",
    "    warmup_steps=10000,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=0.00005,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.999,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/jatavathpavannaik/anaconda3/envs/Bert/lib/python3.11/site-packages/transformers/trainer_tf.py:118: FutureWarning: The class `TFTrainer` is deprecated and will be removed in version 5 of Transformers. We recommend using native Keras instead, by calling methods like `fit()` and `predict()` directly on the model object. Detailed examples of the Keras style can be found in our examples at https://github.com/huggingface/transformers/tree/main/examples/tensorflow\n",
      "  warnings.warn(\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    }
   ],
   "source": [
    "with training_args.strategy.scope(): ## for distributed computation\n",
    "    model=TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=3)\n",
    "trainer=TFTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08871742912956902}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.5105443,  5.800942 , -2.30606  ],\n",
       "       [-2.283487 ,  5.63539  , -2.3454142],\n",
       "       [-1.1193345,  3.5720348, -1.8683442],\n",
       "       ...,\n",
       "       [-3.2836652, -1.5765861,  4.5037684],\n",
       "       [-2.6568682,  5.6865735, -2.0188594],\n",
       "       [-2.547587 , -2.4784482,  4.372288 ]], dtype=float32), label_ids=array([1., 1., 1., ..., 2., 1., 2.], dtype=float32), metrics={'eval_loss': 0.08876561688947247})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    }
   ],
   "source": [
    "output=trainer.predict(test_dataset)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7011,    0,    0],\n",
       "       [   0, 7172,    0],\n",
       "       [   0,    0, 7123]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the model and using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name,num_labels=3)\n",
    "\n",
    "model.load_weights('/Users/jatavathpavannaik/Documents/python/Bert/final_model/tf_model.h5')\n",
    "\n",
    "text = \"i a\"\n",
    "tokenized_input = tokenizer(text, return_tensors='tf')\n",
    "\n",
    "outputs = model(tokenized_input['input_ids'])\n",
    "\n",
    "probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "predicted_class = tf.argmax(probabilities, axis=-1).numpy().item()\n",
    "print(f'Predicted class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"/Users/jatavathpavannaik/Documents/python/Bert/Reddit_Data.csv\")\n",
    "data=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       " 1    15830\n",
       " 0    13142\n",
       "-1     8277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       " 1    228\n",
       " 0    167\n",
       "-1    105\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'] == -1, 'category'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"what the fuck\"\n",
    "tokenized_input = tokenizer(text, return_tensors='tf')\n",
    "outputs = model(tokenized_input['input_ids'])\n",
    "probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "predicted_class = tf.argmax(probabilities, axis=-1).numpy().item()\n",
    "\n",
    "model_data=[]\n",
    "model_data.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def predict_class(row):\n",
    "    tokenized_input = tokenizer(str(row['clean_comment']), return_tensors='tf')\n",
    "    outputs = model(tokenized_input['input_ids'])\n",
    "    probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy().item()\n",
    "    return predicted_class\n",
    "model.load_weights(\"/Users/jatavathpavannaik/Documents/python/Bert/final_model/tf_model.h5\")\n",
    "# Apply the function to each row in the DataFrame and store the result in a new column 'predicted_class'\n",
    "df['predicted_class'] = df.apply(predict_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert_classification_metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       167\n",
      "           1       0.98      0.98      0.98       228\n",
      "           2       0.95      0.99      0.97       105\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.97      0.98      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      " \n",
      "\n",
      "confusion_metrics: \n",
      " [[162   3   2]\n",
      " [  2 223   3]\n",
      " [  0   1 104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Bert_classification_metrics = metrics.classification_report(df[\"category\"], df[\"predicted_class\"])\n",
    "print(\"Bert_classification_metrics: \\n\",Bert_classification_metrics, '\\n')\n",
    "confusion_metrics = metrics.confusion_matrix(df[\"category\"], df[\"predicted_class\"])\n",
    "print(\"confusion_metrics: \\n\",confusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(df[\"category\"],df[\"predicted_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/Users/jatavathpavannaik/Documents/python/Bert/training.1600000.processed.noemoticon.csv\",encoding=\"latin-1\")\n",
    "data=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1467810369', 'Mon Apr 06 22:19:45 PDT 2009', 'NO_QUERY',\n",
       "       '_TheSpecialOne_',\n",
       "       '@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[[\"0\",\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/9v3n4s817s5g5rw62jzf3hlr0000gn/T/ipykernel_750/1331922322.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.rename(columns={\"0\":\"category\",\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\":\"text\"},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.rename(columns={\"0\":\"category\",\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\":\"text\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "4    800000\n",
       "0    799999\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0    258\n",
       "4    242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(row):\n",
    "    tokenized_input = tokenizer(str(row['text']), return_tensors='tf')\n",
    "    outputs = model(tokenized_input['input_ids'])\n",
    "    probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy().item()\n",
    "    return predicted_class\n",
    "model.load_weights(\"/Users/jatavathpavannaik/Documents/python/Bert/final_model/tf_model.h5\")\n",
    "# Apply the function to each row in the DataFrame and store the result in a new column 'predicted_class'\n",
    "data['predicted_class'] = data.apply(predict_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1254693</th>\n",
       "      <td>4</td>\n",
       "      <td>@khali_blache  Hello..you like Tom waits i see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254467</th>\n",
       "      <td>4</td>\n",
       "      <td>Congratulations to ohjoy! On 10K cache finds  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599107</th>\n",
       "      <td>4</td>\n",
       "      <td>@ZAC_DANCE macbook, or macbook pro? either way...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799276</th>\n",
       "      <td>0</td>\n",
       "      <td>What're we doing?!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700924</th>\n",
       "      <td>0</td>\n",
       "      <td>Ugh, I hate soldier flys.  Stupid things scare...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245137</th>\n",
       "      <td>0</td>\n",
       "      <td>ok celeb gossip sites too</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065166</th>\n",
       "      <td>4</td>\n",
       "      <td>@SuziQoregon It was probably just me!  It work...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906316</th>\n",
       "      <td>4</td>\n",
       "      <td>@Nickems that would be great!!!  thanks!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988517</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm getting a little bit excited... I'm gettin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462395</th>\n",
       "      <td>4</td>\n",
       "      <td>@srkneo u do! her movies r amazing! john tucke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               text  \\\n",
       "1254693         4  @khali_blache  Hello..you like Tom waits i see...   \n",
       "1254467         4  Congratulations to ohjoy! On 10K cache finds  ...   \n",
       "1599107         4  @ZAC_DANCE macbook, or macbook pro? either way...   \n",
       "799276          0                                What're we doing?!    \n",
       "700924          0  Ugh, I hate soldier flys.  Stupid things scare...   \n",
       "...           ...                                                ...   \n",
       "245137          0                         ok celeb gossip sites too    \n",
       "1065166         4  @SuziQoregon It was probably just me!  It work...   \n",
       "906316          4          @Nickems that would be great!!!  thanks!!   \n",
       "988517          4  I'm getting a little bit excited... I'm gettin...   \n",
       "1462395         4  @srkneo u do! her movies r amazing! john tucke...   \n",
       "\n",
       "         predicted_class  \n",
       "1254693                0  \n",
       "1254467                1  \n",
       "1599107                1  \n",
       "799276                 0  \n",
       "700924                 2  \n",
       "...                  ...  \n",
       "245137                 0  \n",
       "1065166                2  \n",
       "906316                 1  \n",
       "988517                 1  \n",
       "1462395                1  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_class\n",
       "1    220\n",
       "0    155\n",
       "2    125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"predicted_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"category\"]==0,'category'] = 2\n",
    "data.loc[data[\"category\"]==4,'category'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert_classification_metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.62      0.57      0.59       242\n",
      "           2       0.76      0.37      0.50       258\n",
      "\n",
      "    accuracy                           0.46       500\n",
      "   macro avg       0.46      0.31      0.36       500\n",
      "weighted avg       0.69      0.46      0.54       500\n",
      " \n",
      "\n",
      "confusion_metrics: \n",
      " [[  0   0   0]\n",
      " [ 75 137  30]\n",
      " [ 80  83  95]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jatavathpavannaik/anaconda3/envs/Bert/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jatavathpavannaik/anaconda3/envs/Bert/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jatavathpavannaik/anaconda3/envs/Bert/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Bert_classification_metrics = metrics.classification_report(data[\"category\"], data[\"predicted_class\"])\n",
    "print(\"Bert_classification_metrics: \\n\",Bert_classification_metrics, '\\n')\n",
    "confusion_metrics = metrics.confusion_matrix(data[\"category\"], data[\"predicted_class\"])\n",
    "print(\"confusion_metrics: \\n\",confusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[(data[\"predicted_class\"] == 1) | (data[\"predicted_class\"] == 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@rioblaze awww... thanks...Even thought I can't figure out to put a picture up hurr.. \""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][291164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672463768115942"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(df[\"category\"],df[\"predicted_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### airline sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"/Users/jatavathpavannaik/Documents/python/Bert/Tweets.csv\")\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"airline_sentiment\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    317\n",
       "neutral      99\n",
       "positive     84\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jatavathpavannaik/anaconda3/envs/Bert/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-06 12:27:15.426538: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-06 12:27:15.426563: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-06 12:27:15.426571: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-06 12:27:15.426915: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-06 12:27:15.427373: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name,num_labels=3)\n",
    "\n",
    "model.load_weights('/Users/jatavathpavannaik/Documents/python/Bert/final_model/tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(row):\n",
    "    tokenized_input = tokenizer(str(row['text']), return_tensors='tf')\n",
    "    outputs = model(tokenized_input['input_ids'])\n",
    "    probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy().item()\n",
    "    return predicted_class\n",
    "model.load_weights(\"/Users/jatavathpavannaik/Documents/python/Bert/final_model/tf_model.h5\")\n",
    "# Apply the function to each row in the DataFrame and store the result in a new column 'predicted_class'\n",
    "df['predicted_class'] = df.apply(predict_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"airline_sentiment\"]==\"negative\", \"airline_sentiment\"]=2\n",
    "df.loc[df[\"airline_sentiment\"]==\"positive\", \"airline_sentiment\"]=1\n",
    "df.loc[df[\"airline_sentiment\"]==\"neutral\", \"airline_sentiment\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 7538 to 10758\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   airline_sentiment  500 non-null    object\n",
      " 1   text               500 non-null    object\n",
      " 2   predicted_class    500 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 15.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert_classification_metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.55      0.39        99\n",
      "           1       0.36      0.74      0.49        84\n",
      "           2       0.90      0.44      0.59       317\n",
      "\n",
      "    accuracy                           0.51       500\n",
      "   macro avg       0.52      0.57      0.49       500\n",
      "weighted avg       0.69      0.51      0.53       500\n",
      " \n",
      "\n",
      "confusion_metrics: \n",
      " [[ 54  34  11]\n",
      " [ 17  62   5]\n",
      " [105  74 138]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Bert_classification_metrics = metrics.classification_report(df[\"airline_sentiment\"].astype(int), df[\"predicted_class\"])\n",
    "print(\"Bert_classification_metrics: \\n\",Bert_classification_metrics, '\\n')\n",
    "confusion_metrics = metrics.confusion_matrix(df[\"airline_sentiment\"].astype(int), df[\"predicted_class\"])\n",
    "print(\"confusion_metrics: \\n\",confusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(df[\"airline_sentiment\"].astype(int), df[\"predicted_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparision of distilbert base and our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"/Users/jatavathpavannaik/Documents/python/Bert/Tweets.csv\")\n",
    "df=pd.DataFrame(data)\n",
    "df=df[[\"airline_sentiment\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[(df[\"airline_sentiment\"]==\"negative\") | (df[\"airline_sentiment\"]==\"positive\") ]\n",
    "df=df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    402\n",
       "positive     98\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name,num_labels=3)\n",
    "\n",
    "model.load_weights('/Users/jatavathpavannaik/Documents/python/Bert/final_model/tf_model.h5')\n",
    "\n",
    "text = \"The photo is of today when my dog ​​was unable to urinate, then we went to  BVC college & hospital at  am, then the guard said that the hospital is closed today, so I asked if emergency is also closed, then said yes everything is closed? yadavtejashwi ji plz speak.\"\n",
    "tokenized_input = tokenizer(text, return_tensors='tf')\n",
    "\n",
    "outputs = model(tokenized_input['input_ids'])\n",
    "\n",
    "probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "predicted_class = tf.argmax(probabilities, axis=-1).numpy().item()\n",
    "print(f'Predicted class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.00988188, 0.01722025, 0.97289795]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998007416725159}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9994704127311707}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9985482096672058}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(\"Possibly rate per job, as cut money, has been fixed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.5153689384460449}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(\"congratulations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel(\"/Users/jatavathpavannaik/Documents/python/Bert/Data_Set.xlsx\",sheet_name=\"test\")\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>len_of_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why should she be referred to as \"My Lord\"?</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: and she did that I have also voted for her</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Call him Chenal Ghosh which suits that Joker</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knowledge is power. thank you. God bless you.</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>she learnt how to feed them with our Tax money</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>One more. Fact here the cases are of rd mutati...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>I agree with you. BJP hatao Bharat bachao RSS ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>It is very unfortunately matter which was happ...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Time will tell who was right and acted as per ...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>People fear to lodge complaint that they had g...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  len_of_text\n",
       "0          Why should she be referred to as \"My Lord\"?           43\n",
       "1         : and she did that I have also voted for her           44\n",
       "2         Call him Chenal Ghosh which suits that Joker           44\n",
       "3        Knowledge is power. thank you. God bless you.           45\n",
       "4      she learnt how to feed them with our Tax money            47\n",
       "..                                                 ...          ...\n",
       "494  One more. Fact here the cases are of rd mutati...           64\n",
       "495  I agree with you. BJP hatao Bharat bachao RSS ...           64\n",
       "496  It is very unfortunately matter which was happ...           65\n",
       "497  Time will tell who was right and acted as per ...           65\n",
       "498  People fear to lodge complaint that they had g...           65\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(row):\n",
    "    tokenized_input = tokenizer(str(row['Text']), return_tensors='tf')\n",
    "    outputs = model(tokenized_input['input_ids'])\n",
    "    probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy().item()\n",
    "    return predicted_class\n",
    "model.load_weights(\"/Users/jatavathpavannaik/Documents/python/Bert/final_model/tf_model.h5\")\n",
    "# Apply the function to each row in the DataFrame and store the result in a new column 'predicted_class'\n",
    "df['predicted_class'] = df.apply(predict_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "df.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
