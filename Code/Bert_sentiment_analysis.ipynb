{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanTxt(text):\n",
    "    text = re.sub('@[A-Za-z0–9]+', '', text) #Removing @mentions\n",
    "    text = re.sub('#', '', text) # Removing '#' hash tag\n",
    "    text = re.sub('RT[\\s]+', '', text) # Removing RT\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlink\n",
    "    # to remove ',', '.', '!', '?', ';', ':', '(', ')', '[', ']', '{', '}', '-', '_', '*', '/', '\\', '|', '~', '`', '+', '=', '<', '>', '^', '&', '$', '#', '@', '©', '®', '™', '°', '•', '…'\n",
    "    text = re.sub('[^\\w\\s]','',text)\n",
    "    text = re.sub('/\\S+', '', text) # Removing hyperlink\n",
    "    text = re.sub('\\s+', ' ', text) # Removing multiple spaces\n",
    "    text = text.lower() # Converting to lowercase\n",
    "    text = text.strip() # Removing trailing spaces\n",
    "    text = text.replace('\\n', ' ') # Removing newline character\n",
    "    # to remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stpwrd])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"LABEL_0\": \"negative\",\n",
    "    \"LABEL_1\": \"positive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_Bert(reviews):\n",
    "    try:\n",
    "        reviews = cleanTxt(reviews)\n",
    "    except:\n",
    "        pass\n",
    "    sentiments = sentiment_pipeline(reviews)\n",
    "    l = sentiments[0]['label']\n",
    "    s = sentiments[0]['score']\n",
    "    # return str(l).lower()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment_Bert(\"i am a good boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel(\"/Users/jatavathpavannaik/Documents/python/Bert/Data_sets/test_data.xlsx\")\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    try:\n",
    "        sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    # return sentiment_dict\n",
    "        if sentiment_dict['compound'] >= 0.1 :\n",
    "            return \"positive\",sentiment_dict[\"compound\"]\n",
    "\n",
    "        elif sentiment_dict['compound'] <= - 0.02 :\n",
    "            \n",
    "            return \"negative\",sentiment_dict['compound']\n",
    "\n",
    "        else :\n",
    "            return \"neutral\",sentiment_dict['compound']\n",
    "    except Exception as e:\n",
    "        print({e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_vader_score']=df['comments_without_emojis'].apply(lambda x: sentiment_scores(x)[1])\n",
    "df['sentiment_vader_label']=df['comments_without_emojis'].apply(lambda x: sentiment_scores(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_vader_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = df[df['sentiment_vader_label'] == 'positive']\n",
    "negative_df = df[df['sentiment_vader_label'] == 'negative']\n",
    "neutral_df = df[df['sentiment_vader_label'] == 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df=positive_df.sample(166)\n",
    "negative_df=negative_df.sample(167)\n",
    "neutral_df=neutral_df.sample(167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conat=pd.concat([positive_df,negative_df,neutral_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conat['comments_without_emojis'] = conat['comments_without_emojis'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conat['sentiment_Bert_Model_score']=conat[\"comments_without_emojis\"].astype(str).apply(lambda x: get_sentiment_Bert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conat['sentiment_Bert_Model_label']=conat[\"comments_without_emojis\"].astype(str).apply(lambda x: get_sentiment_Bert(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conat[\"sentiment_Bert_Model_label\"]=conat[\"sentiment_Bert_Model_label\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "sentiment_dict = sid_obj.polarity_scores(\"i am a good boy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline(\"i am good boy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data=pd.read_excel(\"/Users/jatavathpavannaik/Documents/python/Bert/Data_sets/Bert_Vader.xlsx\")\n",
    "# bv=pd.DataFrame(data)\n",
    "bv=conat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# condition = (bv[\"sentiment_vader_score\"] <= 0.5) & (bv[\"sentiment_vader_score\"] >= -0.5)\n",
    "\n",
    "# bv[\"label\"] = np.where(condition & (bv[\"sentiment_Bert_Model_score\"] >= 0.99),\n",
    "#                        bv[\"sentiment_Bert_Model_label\"],\n",
    "#                        \"neutral\")\n",
    "\n",
    "\n",
    "# bv.loc[~condition, \"label\"] = bv[\"sentiment_Bert_Model_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "condition = (bv[\"sentiment_vader_score\"] == 0)\n",
    "\n",
    "bv[\"label\"] = np.where(condition,\n",
    "                       \"neutral\",bv[\"sentiment_Bert_Model_label\"])\n",
    "\n",
    "\n",
    "bv.loc[~condition, \"label\"] = bv[\"sentiment_Bert_Model_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv[\"sentiment_vader_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "Bert_classification_metrics = metrics.classification_report(bv[\"sentiment_vader_label\"], bv[\"label\"])\n",
    "print(\"Bert_classification_metrics: \\n\",Bert_classification_metrics, '\\n')\n",
    "confusion_metrics = metrics.confusion_matrix(bv[\"sentiment_vader_label\"], bv[\"label\"])\n",
    "print(\"confusion_metrics: \\n\",confusion_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tw=pd.read_csv(\"/Users/jatavathpavannaik/Documents/python/Bert/English_YT_comments.xlsx\")\n",
    "tw=pd.DataFrame(tw)\n",
    "tw=tw.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming tw is your DataFrame\n",
    "# Assuming \"category\" is the column you want to use for mapping\n",
    "\n",
    "# Use np.select to create a new column based on conditions\n",
    "tw['sentiment_label'] = np.select(\n",
    "    [tw['category'] == 1, tw['category'] == -1, tw['category'] == 0],\n",
    "    ['positive', 'negative', 'neutral'],\n",
    "    default='undefined'  # You can choose a default label for other cases\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_Bert(reviews):\n",
    "    try:\n",
    "        reviews = cleanTxt(reviews)\n",
    "    except:\n",
    "        pass\n",
    "    sentiments = sentiment_pipeline(reviews)\n",
    "    l = sentiments[0]['label']\n",
    "    s = sentiments[0]['score']\n",
    "    # return str(l).lower()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw['sentiment_vader_score']=tw['clean_text'].apply(lambda x: sentiment_scores(x)[1])\n",
    "tw['sentiment_vader_label']=tw['clean_text'].apply(lambda x: sentiment_scores(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw['sentiment_Bert_Model_score']=tw[\"clean_text\"].astype(str).apply(lambda x: get_sentiment_Bert(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw['sentiment_Bert_Model_label']=tw[\"clean_text\"].astype(str).apply(lambda x: get_sentiment_Bert(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv=tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "condition = (bv[\"sentiment_vader_score\"] == 0)\n",
    "\n",
    "bv[\"label\"] = np.where(condition,\n",
    "                       \"neutral\",bv[\"sentiment_Bert_Model_label\"])\n",
    "\n",
    "\n",
    "bv.loc[~condition, \"label\"] = bv[\"sentiment_Bert_Model_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv[\"sentiment_Bert_Model_label\"]=bv[\"sentiment_Bert_Model_label\"].str.lower()\n",
    "bv[\"label\"]=bv[\"label\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "Bert_classification_metrics = metrics.classification_report(bv[\"sentiment_label\"], bv[\"label\"])\n",
    "print(\"Bert_classification_metrics: \\n\",Bert_classification_metrics, '\\n')\n",
    "confusion_metrics = metrics.confusion_matrix(bv[\"sentiment_label\"], bv[\"label\"])\n",
    "print(\"confusion_metrics: \\n\",confusion_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### youtube ysrcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel(\"/Users/jatavathpavannaik/Documents/python/Bert/Phase_2_Translated_text_Youtube_hashtag_comments_24Feb_25Feb.xlsx\")\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[df[\"consol_lang_tag\"]==\"en\"]\n",
    "# df.rename(columns={\"Preprocessed_text\":\"translated_text\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"translated_text\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=\"translated_text\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={\"Preprocessed_text\":\"translated_text\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>author_channel_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>id1</th>\n",
       "      <th>comment</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>party</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>Html_tags_removed</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lang</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lower_comment</th>\n",
       "      <th>Punctuation_removed</th>\n",
       "      <th>whitespace_removed</th>\n",
       "      <th>stop_words_removed</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>sentiment_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>65dd95978ede59313b460851</td>\n",
       "      <td>UCiHhoalS6Styu-HunXIOQpw</td>\n",
       "      <td>rRRSEMy2Cyo</td>\n",
       "      <td>UgzQHlyc4zGVMhN1ASt4AaABAg</td>\n",
       "      <td>అడుడం ఆంధ్ర పుణ్యమా అంటూ విజయనగరం నుండి ఒక సామ...</td>\n",
       "      <td>2024-02-25 06:35:58</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-27 01:24:52</td>\n",
       "      <td>అడుడం ఆంధ్ర పుణ్యమా అంటూ విజయనగరం నుండి ఒక సామ...</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__te</td>\n",
       "      <td>1.00</td>\n",
       "      <td>te</td>\n",
       "      <td>Dhoni's Chance in CSK Team from Vijayanagaram</td>\n",
       "      <td>dhoni's chance in csk team from vijayanagaram</td>\n",
       "      <td>dhonis chance in csk team from vijayanagaram</td>\n",
       "      <td>dhonis chance in csk team from vijayanagaram</td>\n",
       "      <td>dhonis chance csk team vijayanagaram</td>\n",
       "      <td>dhonis chance csk team vijayanagaram</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65dd95978ede59313b460852</td>\n",
       "      <td>UCeL4EY4a2lAJMu9LguQxaMQ</td>\n",
       "      <td>rRRSEMy2Cyo</td>\n",
       "      <td>UgzLpooj1SvITHfHe914AaABAg</td>\n",
       "      <td>commentary 🤣🤣🤣🤣🤣</td>\n",
       "      <td>2024-02-25 05:55:51</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-27 01:24:52</td>\n",
       "      <td>commentary 🤣🤣🤣🤣🤣</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.82</td>\n",
       "      <td>en</td>\n",
       "      <td>commentary</td>\n",
       "      <td>commentary</td>\n",
       "      <td>commentary</td>\n",
       "      <td>commentary</td>\n",
       "      <td>commentary</td>\n",
       "      <td>commentary</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65dd95978ede59313b460853</td>\n",
       "      <td>UCL6aHHP-1098sMmqSvnGcNw</td>\n",
       "      <td>rRRSEMy2Cyo</td>\n",
       "      <td>UgyBZ_37volR5Z3CexR4AaABAg</td>\n",
       "      <td>Adudaam Andhra lo selected persons ke chance i...</td>\n",
       "      <td>2024-02-25 02:15:35</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-27 01:24:52</td>\n",
       "      <td>Adudaam Andhra lo selected persons ke chance i...</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.43</td>\n",
       "      <td>en</td>\n",
       "      <td>Adudaam Andhra lo selected persons ke chance i...</td>\n",
       "      <td>adudaam andhra lo selected persons ke chance i...</td>\n",
       "      <td>adudaam andhra lo selected persons ke chance i...</td>\n",
       "      <td>adudaam andhra lo selected persons ke chance i...</td>\n",
       "      <td>adudaam andhra lo selected persons ke chance i...</td>\n",
       "      <td>adudaam andhra lo selected person ke chance ic...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>65dd95978ede59313b460ab1</td>\n",
       "      <td>UCmf0Ti8HvbKxMxNqG6wc4FA</td>\n",
       "      <td>-DzXX8ZUH54</td>\n",
       "      <td>Ugzq9QRQUlKL840ltiZ4AaABAg</td>\n",
       "      <td>E channel ki andharu report kottanddi</td>\n",
       "      <td>2024-02-24 08:36:25</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-27 01:24:52</td>\n",
       "      <td>E channel ki andharu report kottanddi</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.73</td>\n",
       "      <td>en</td>\n",
       "      <td>E channel ki andharu report kottanddi</td>\n",
       "      <td>e channel ki andharu report kottanddi</td>\n",
       "      <td>e channel ki andharu report kottanddi</td>\n",
       "      <td>e channel ki andharu report kottanddi</td>\n",
       "      <td>e channel ki andharu report kottanddi</td>\n",
       "      <td>e channel ki andharu report kottanddi</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>65dd95978ede59313b460ab2</td>\n",
       "      <td>UCmf0Ti8HvbKxMxNqG6wc4FA</td>\n",
       "      <td>-DzXX8ZUH54</td>\n",
       "      <td>UgyOfU5micx2P3BjQVp4AaABAg</td>\n",
       "      <td>Bro andhari ki chepthuna idhi fake news .jagan...</td>\n",
       "      <td>2024-02-24 08:34:42</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-27 01:24:52</td>\n",
       "      <td>Bro andhari ki chepthuna idhi fake news .jagan...</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.43</td>\n",
       "      <td>en</td>\n",
       "      <td>Bro andhari ki chepthuna idhi fake news .jagan...</td>\n",
       "      <td>bro andhari ki chepthuna idhi fake news .jagan...</td>\n",
       "      <td>bro andhari ki chepthuna idhi fake news jagan ...</td>\n",
       "      <td>bro andhari ki chepthuna idhi fake news jagan ...</td>\n",
       "      <td>bro andhari ki chepthuna idhi fake news jagan ...</td>\n",
       "      <td>bro andhari ki chepthuna idhi fake news jagan ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17898</th>\n",
       "      <td>18040</td>\n",
       "      <td>65e07d16d3e0d87287fe7060</td>\n",
       "      <td>UC6fXXdIVR-zw03EC_NF6CZQ</td>\n",
       "      <td>T2M4NEAuAeE</td>\n",
       "      <td>UgyHc3ms9ycwuLxUhfV4AaABAg</td>\n",
       "      <td>Eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>2024-02-24 10:28:40</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-29 06:18:13</td>\n",
       "      <td>Eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.22</td>\n",
       "      <td>en</td>\n",
       "      <td>Eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>eppudu eddaru kalisi vocharu next inka entha m...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17899</th>\n",
       "      <td>18041</td>\n",
       "      <td>65e07d16d3e0d87287fe7061</td>\n",
       "      <td>UCgj1IMG5noI1GjDdDq_O_GQ</td>\n",
       "      <td>T2M4NEAuAeE</td>\n",
       "      <td>UgwNqONf4PMObj2129t4AaABAg</td>\n",
       "      <td>Orey mundu aa 24 seats gelipinchandira chalu</td>\n",
       "      <td>2024-02-24 10:28:26</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-29 06:18:13</td>\n",
       "      <td>Orey mundu aa 24 seats gelipinchandira chalu</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.60</td>\n",
       "      <td>en</td>\n",
       "      <td>Orey mundu aa  seats gelipinchandira chalu</td>\n",
       "      <td>orey mundu aa  seats gelipinchandira chalu</td>\n",
       "      <td>orey mundu aa  seats gelipinchandira chalu</td>\n",
       "      <td>orey mundu aa  seats gelipinchandira chalu</td>\n",
       "      <td>orey mundu aa seats gelipinchandira chalu</td>\n",
       "      <td>orey mundu aa seat gelipinchandira chalu</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17900</th>\n",
       "      <td>18042</td>\n",
       "      <td>65e07d16d3e0d87287fe7062</td>\n",
       "      <td>UCrn4a7lHQ1BpEy4FxMadWUA</td>\n",
       "      <td>T2M4NEAuAeE</td>\n",
       "      <td>UgwTNJ9t7vpCXUf5ztt4AaABAg</td>\n",
       "      <td>Na mogga nachite pettukoava</td>\n",
       "      <td>2024-02-24 10:27:36</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-29 06:18:13</td>\n",
       "      <td>Na mogga nachite pettukoava</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__fi</td>\n",
       "      <td>0.42</td>\n",
       "      <td>fi</td>\n",
       "      <td>Na mogga nachite deceitive</td>\n",
       "      <td>na mogga nachite deceitive</td>\n",
       "      <td>na mogga nachite deceitive</td>\n",
       "      <td>na mogga nachite deceitive</td>\n",
       "      <td>na mogga nachite deceitive</td>\n",
       "      <td>na mogga nachite deceitive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17901</th>\n",
       "      <td>18043</td>\n",
       "      <td>65e07d16d3e0d87287fe7063</td>\n",
       "      <td>UCthT9bMFoJs0cXAs2V8iwrg</td>\n",
       "      <td>T2M4NEAuAeE</td>\n",
       "      <td>Ugxa38IqmUXtjDUAZ4h4AaABAg</td>\n",
       "      <td>Asamardisrhuna.. Nuv oka asamardhydu vadu ok a...</td>\n",
       "      <td>2024-02-24 10:26:49</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-29 06:18:13</td>\n",
       "      <td>Asamardisrhuna.. Nuv oka asamardhydu vadu ok a...</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.46</td>\n",
       "      <td>en</td>\n",
       "      <td>Asamardisrhuna.. Nuv oka asamardhydu vadu ok a...</td>\n",
       "      <td>asamardisrhuna.. nuv oka asamardhydu vadu ok a...</td>\n",
       "      <td>asamardisrhuna nuv oka asamardhydu vadu ok asa...</td>\n",
       "      <td>asamardisrhuna nuv oka asamardhydu vadu ok asa...</td>\n",
       "      <td>asamardisrhuna nuv oka asamardhydu vadu ok asa...</td>\n",
       "      <td>asamardisrhuna nuv oka asamardhydu vadu ok asa...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17902</th>\n",
       "      <td>18044</td>\n",
       "      <td>65e07d16d3e0d87287fe7064</td>\n",
       "      <td>UCz0PcQSbWTl8joExcMo99-A</td>\n",
       "      <td>T2M4NEAuAeE</td>\n",
       "      <td>UgwUzyqlWYhBEjJ-HpJ4AaABAg</td>\n",
       "      <td>👌రేయ్ టిడిపి జెండా మోసేది కూలి డబ్బులికే కదా మ...</td>\n",
       "      <td>2024-02-24 10:08:13</td>\n",
       "      <td>TDP</td>\n",
       "      <td>2024-02-29 06:18:13</td>\n",
       "      <td>👌రేయ్ టిడిపి జెండా మోసేది కూలి డబ్బులికే కదా మ...</td>\n",
       "      <td>...</td>\n",
       "      <td>__label__te</td>\n",
       "      <td>1.00</td>\n",
       "      <td>te</td>\n",
       "      <td>Ray TDP flag bearing money, you, our flag, wil...</td>\n",
       "      <td>ray tdp flag bearing money, you, our flag, wil...</td>\n",
       "      <td>ray tdp flag bearing money you our flag will g...</td>\n",
       "      <td>ray tdp flag bearing money you our flag will g...</td>\n",
       "      <td>ray tdp flag bearing money flag give paisa pai...</td>\n",
       "      <td>ray tdp flag bearing money flag give paisa pai...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17903 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                       _id         author_channel_id  \\\n",
       "0               0  65dd95978ede59313b460851  UCiHhoalS6Styu-HunXIOQpw   \n",
       "1               1  65dd95978ede59313b460852  UCeL4EY4a2lAJMu9LguQxaMQ   \n",
       "2               2  65dd95978ede59313b460853  UCL6aHHP-1098sMmqSvnGcNw   \n",
       "3               3  65dd95978ede59313b460ab1  UCmf0Ti8HvbKxMxNqG6wc4FA   \n",
       "4               4  65dd95978ede59313b460ab2  UCmf0Ti8HvbKxMxNqG6wc4FA   \n",
       "...           ...                       ...                       ...   \n",
       "17898       18040  65e07d16d3e0d87287fe7060  UC6fXXdIVR-zw03EC_NF6CZQ   \n",
       "17899       18041  65e07d16d3e0d87287fe7061  UCgj1IMG5noI1GjDdDq_O_GQ   \n",
       "17900       18042  65e07d16d3e0d87287fe7062  UCrn4a7lHQ1BpEy4FxMadWUA   \n",
       "17901       18043  65e07d16d3e0d87287fe7063  UCthT9bMFoJs0cXAs2V8iwrg   \n",
       "17902       18044  65e07d16d3e0d87287fe7064  UCz0PcQSbWTl8joExcMo99-A   \n",
       "\n",
       "          video_id                         id1  \\\n",
       "0      rRRSEMy2Cyo  UgzQHlyc4zGVMhN1ASt4AaABAg   \n",
       "1      rRRSEMy2Cyo  UgzLpooj1SvITHfHe914AaABAg   \n",
       "2      rRRSEMy2Cyo  UgyBZ_37volR5Z3CexR4AaABAg   \n",
       "3      -DzXX8ZUH54  Ugzq9QRQUlKL840ltiZ4AaABAg   \n",
       "4      -DzXX8ZUH54  UgyOfU5micx2P3BjQVp4AaABAg   \n",
       "...            ...                         ...   \n",
       "17898  T2M4NEAuAeE  UgyHc3ms9ycwuLxUhfV4AaABAg   \n",
       "17899  T2M4NEAuAeE  UgwNqONf4PMObj2129t4AaABAg   \n",
       "17900  T2M4NEAuAeE  UgwTNJ9t7vpCXUf5ztt4AaABAg   \n",
       "17901  T2M4NEAuAeE  Ugxa38IqmUXtjDUAZ4h4AaABAg   \n",
       "17902  T2M4NEAuAeE  UgwUzyqlWYhBEjJ-HpJ4AaABAg   \n",
       "\n",
       "                                                 comment        publish_date  \\\n",
       "0      అడుడం ఆంధ్ర పుణ్యమా అంటూ విజయనగరం నుండి ఒక సామ... 2024-02-25 06:35:58   \n",
       "1                                       commentary 🤣🤣🤣🤣🤣 2024-02-25 05:55:51   \n",
       "2      Adudaam Andhra lo selected persons ke chance i... 2024-02-25 02:15:35   \n",
       "3                  E channel ki andharu report kottanddi 2024-02-24 08:36:25   \n",
       "4      Bro andhari ki chepthuna idhi fake news .jagan... 2024-02-24 08:34:42   \n",
       "...                                                  ...                 ...   \n",
       "17898  Eppudu eddaru kalisi vocharu next inka entha m... 2024-02-24 10:28:40   \n",
       "17899       Orey mundu aa 24 seats gelipinchandira chalu 2024-02-24 10:28:26   \n",
       "17900                        Na mogga nachite pettukoava 2024-02-24 10:27:36   \n",
       "17901  Asamardisrhuna.. Nuv oka asamardhydu vadu ok a... 2024-02-24 10:26:49   \n",
       "17902  👌రేయ్ టిడిపి జెండా మోసేది కూలి డబ్బులికే కదా మ... 2024-02-24 10:08:13   \n",
       "\n",
       "      party         upload_date  \\\n",
       "0       TDP 2024-02-27 01:24:52   \n",
       "1       TDP 2024-02-27 01:24:52   \n",
       "2       TDP 2024-02-27 01:24:52   \n",
       "3       TDP 2024-02-27 01:24:52   \n",
       "4       TDP 2024-02-27 01:24:52   \n",
       "...     ...                 ...   \n",
       "17898   TDP 2024-02-29 06:18:13   \n",
       "17899   TDP 2024-02-29 06:18:13   \n",
       "17900   TDP 2024-02-29 06:18:13   \n",
       "17901   TDP 2024-02-29 06:18:13   \n",
       "17902   TDP 2024-02-29 06:18:13   \n",
       "\n",
       "                                       Html_tags_removed  ...     language  \\\n",
       "0      అడుడం ఆంధ్ర పుణ్యమా అంటూ విజయనగరం నుండి ఒక సామ...  ...  __label__te   \n",
       "1                                       commentary 🤣🤣🤣🤣🤣  ...  __label__en   \n",
       "2      Adudaam Andhra lo selected persons ke chance i...  ...  __label__en   \n",
       "3                  E channel ki andharu report kottanddi  ...  __label__en   \n",
       "4      Bro andhari ki chepthuna idhi fake news .jagan...  ...  __label__en   \n",
       "...                                                  ...  ...          ...   \n",
       "17898  Eppudu eddaru kalisi vocharu next inka entha m...  ...  __label__en   \n",
       "17899       Orey mundu aa 24 seats gelipinchandira chalu  ...  __label__en   \n",
       "17900                        Na mogga nachite pettukoava  ...  __label__fi   \n",
       "17901  Asamardisrhuna.. Nuv oka asamardhydu vadu ok a...  ...  __label__en   \n",
       "17902  👌రేయ్ టిడిపి జెండా మోసేది కూలి డబ్బులికే కదా మ...  ...  __label__te   \n",
       "\n",
       "      accuracy lang                                    translated_text  \\\n",
       "0         1.00   te      Dhoni's Chance in CSK Team from Vijayanagaram   \n",
       "1         0.82   en                                         commentary   \n",
       "2         0.43   en  Adudaam Andhra lo selected persons ke chance i...   \n",
       "3         0.73   en              E channel ki andharu report kottanddi   \n",
       "4         0.43   en  Bro andhari ki chepthuna idhi fake news .jagan...   \n",
       "...        ...  ...                                                ...   \n",
       "17898     0.22   en  Eppudu eddaru kalisi vocharu next inka entha m...   \n",
       "17899     0.60   en         Orey mundu aa  seats gelipinchandira chalu   \n",
       "17900     0.42   fi                         Na mogga nachite deceitive   \n",
       "17901     0.46   en  Asamardisrhuna.. Nuv oka asamardhydu vadu ok a...   \n",
       "17902     1.00   te  Ray TDP flag bearing money, you, our flag, wil...   \n",
       "\n",
       "                                           lower_comment  \\\n",
       "0          dhoni's chance in csk team from vijayanagaram   \n",
       "1                                             commentary   \n",
       "2      adudaam andhra lo selected persons ke chance i...   \n",
       "3                  e channel ki andharu report kottanddi   \n",
       "4      bro andhari ki chepthuna idhi fake news .jagan...   \n",
       "...                                                  ...   \n",
       "17898  eppudu eddaru kalisi vocharu next inka entha m...   \n",
       "17899         orey mundu aa  seats gelipinchandira chalu   \n",
       "17900                         na mogga nachite deceitive   \n",
       "17901  asamardisrhuna.. nuv oka asamardhydu vadu ok a...   \n",
       "17902  ray tdp flag bearing money, you, our flag, wil...   \n",
       "\n",
       "                                     Punctuation_removed  \\\n",
       "0           dhonis chance in csk team from vijayanagaram   \n",
       "1                                             commentary   \n",
       "2      adudaam andhra lo selected persons ke chance i...   \n",
       "3                  e channel ki andharu report kottanddi   \n",
       "4      bro andhari ki chepthuna idhi fake news jagan ...   \n",
       "...                                                  ...   \n",
       "17898  eppudu eddaru kalisi vocharu next inka entha m...   \n",
       "17899         orey mundu aa  seats gelipinchandira chalu   \n",
       "17900                         na mogga nachite deceitive   \n",
       "17901  asamardisrhuna nuv oka asamardhydu vadu ok asa...   \n",
       "17902  ray tdp flag bearing money you our flag will g...   \n",
       "\n",
       "                                      whitespace_removed  \\\n",
       "0           dhonis chance in csk team from vijayanagaram   \n",
       "1                                             commentary   \n",
       "2      adudaam andhra lo selected persons ke chance i...   \n",
       "3                  e channel ki andharu report kottanddi   \n",
       "4      bro andhari ki chepthuna idhi fake news jagan ...   \n",
       "...                                                  ...   \n",
       "17898  eppudu eddaru kalisi vocharu next inka entha m...   \n",
       "17899         orey mundu aa  seats gelipinchandira chalu   \n",
       "17900                         na mogga nachite deceitive   \n",
       "17901  asamardisrhuna nuv oka asamardhydu vadu ok asa...   \n",
       "17902  ray tdp flag bearing money you our flag will g...   \n",
       "\n",
       "                                      stop_words_removed  \\\n",
       "0                   dhonis chance csk team vijayanagaram   \n",
       "1                                             commentary   \n",
       "2      adudaam andhra lo selected persons ke chance i...   \n",
       "3                  e channel ki andharu report kottanddi   \n",
       "4      bro andhari ki chepthuna idhi fake news jagan ...   \n",
       "...                                                  ...   \n",
       "17898  eppudu eddaru kalisi vocharu next inka entha m...   \n",
       "17899          orey mundu aa seats gelipinchandira chalu   \n",
       "17900                         na mogga nachite deceitive   \n",
       "17901  asamardisrhuna nuv oka asamardhydu vadu ok asa...   \n",
       "17902  ray tdp flag bearing money flag give paisa pai...   \n",
       "\n",
       "                                       preprocessed_text sentiment_vader  \n",
       "0                   dhonis chance csk team vijayanagaram        Positive  \n",
       "1                                             commentary         Neutral  \n",
       "2      adudaam andhra lo selected person ke chance ic...        Positive  \n",
       "3                  e channel ki andharu report kottanddi         Neutral  \n",
       "4      bro andhari ki chepthuna idhi fake news jagan ...        Negative  \n",
       "...                                                  ...             ...  \n",
       "17898  eppudu eddaru kalisi vocharu next inka entha m...         Neutral  \n",
       "17899           orey mundu aa seat gelipinchandira chalu         Neutral  \n",
       "17900                         na mogga nachite deceitive         Neutral  \n",
       "17901  asamardisrhuna nuv oka asamardhydu vadu ok asa...        Positive  \n",
       "17902  ray tdp flag bearing money flag give paisa pai...         Neutral  \n",
       "\n",
       "[17903 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"translated_text\"]=df[\"translated_text\"].str.lower().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"LABEL_0\": \"negative\",\n",
    "    \"LABEL_1\": \"positive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanTxt(text):\n",
    "    text = re.sub('@[A-Za-z0–9]+', '', text) #Removing @mentions\n",
    "    text = re.sub('#', '', text) # Removing '#' hash tag\n",
    "    text = re.sub('$', '', text) # Removing '#' hash tag\n",
    "    text = re.sub('RT[\\s]+', '', text) # Removing RT\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlink\n",
    "    # to remove ',', '.', '!', '?', ';', ':', '(', ')', '[', ']', '{', '}', '-', '_', '*', '/', '\\', '|', '~', '`', '+', '=', '<', '>', '^', '&', '$', '#', '@', '©', '®', '™', '°', '•', '…'\n",
    "    text = re.sub('[^\\w\\s]','',text)\n",
    "    text = re.sub('/\\S+', '', text) # Removing hyperlink\n",
    "    text = re.sub('\\s+', ' ', text) # Removing multiple spaces\n",
    "    text = text.lower() # Converting to lowercase\n",
    "    text = text.strip() # Removing trailing spaces\n",
    "    text = text.replace('\\n', ' ') # Removing newline character\n",
    "    # to remove stopwords\n",
    "    # text = ' '.join([word for word in text.split() if word not in stpwrd])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_Bert(reviews):\n",
    "    try:\n",
    "        reviews = cleanTxt(reviews)\n",
    "    except:\n",
    "        pass\n",
    "    sentiments = sentiment_pipeline(reviews)\n",
    "    l = sentiments[0]['label']\n",
    "    s = sentiments[0]['score']\n",
    "    # return str(l).lower()\n",
    "    return l,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    try:\n",
    "        sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    # return sentiment_dict\n",
    "        if sentiment_dict['compound'] >= 0.1 :\n",
    "            return \"positive\",sentiment_dict[\"compound\"]\n",
    "\n",
    "        elif sentiment_dict['compound'] <= - 0.02 :\n",
    "            \n",
    "            return \"negative\",sentiment_dict['compound']\n",
    "\n",
    "        else :\n",
    "            return \"neutral\",sentiment_dict['compound']\n",
    "    except Exception as e:\n",
    "        print({e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sentiment_vader_label', 'sentiment_vader_score']] = df['translated_text'].apply(sentiment_scores).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jatavathpavannaik/anaconda3/envs/Bert/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-29 18:47:26.357025: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-02-29 18:47:26.357060: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-29 18:47:26.357070: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-29 18:47:26.357142: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-29 18:47:26.357187: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "df[['sentiment_Bert_label', 'sentiment_Bert_score']] = df['translated_text'].apply(get_sentiment_Bert).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_Bert_label\"]=df[\"sentiment_Bert_label\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "condition = ((df[\"sentiment_Bert_score\"] <0.99)&(df[\"sentiment_vader_score\"]<=0.09)&(df[\"sentiment_vader_score\"]>=-0.01))\n",
    "\n",
    "df[\"label\"] = np.where(condition,\n",
    "                       \"neutral\",df[\"sentiment_Bert_label\"])\n",
    "\n",
    "df.loc[~condition, \"label\"] = df[\"sentiment_Bert_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     7366\n",
       "negative    5448\n",
       "positive    5089\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"TDP_sentiment_comments_Hashtags_24Feb_25Feb_2024.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#range(-0.0191,0.0972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
